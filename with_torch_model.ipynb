{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device=device(type='cpu')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "# Commented out because we yet again find mps to be drastically slower\n",
    "# elif torch.backends.mps.is_available():\n",
    "#     torch._dynamo.disable()  # https://github.com/pytorch/pytorch/issues/149184\n",
    "#     device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"{device=}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T15:45:07.031529Z",
     "start_time": "2025-06-07T15:45:06.114087Z"
    }
   },
   "id": "f1f7c192645ed843"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")\n",
    "dataset = load_dataset(\"wikitext\", \"wikitext-103-v1\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T15:45:14.346036Z",
     "start_time": "2025-06-07T15:45:07.032209Z"
    }
   },
   "id": "dcc3bee03e0bf4e3"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "DatasetDict({\n    test: Dataset({\n        features: ['input_ids'],\n        num_rows: 12746\n    })\n    train: Dataset({\n        features: ['input_ids'],\n        num_rows: 5333343\n    })\n    validation: Dataset({\n        features: ['input_ids'],\n        num_rows: 11174\n    })\n})"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from datasets import load_from_disk\n",
    "\n",
    "context_length = 20\n",
    "\n",
    "def tokenize(batch):\n",
    "    # TODO: Sequence packing\n",
    "    outputs = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,\n",
    "        max_length=context_length,\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": [\n",
    "            input_ids\n",
    "            for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"])\n",
    "            if length == context_length\n",
    "        ]\n",
    "    }\n",
    "\n",
    "if Path(\"tokenized-wiki-ds.hf\").exists():\n",
    "    tokenized_ds = load_from_disk(\"tokenized-wiki-ds.hf\")\n",
    "else:\n",
    "    tokenized_ds = dataset.map(\n",
    "        tokenize, batched=True, remove_columns=dataset[\"train\"].column_names\n",
    "    )\n",
    "    tokenized_ds.save_to_disk(\"tokenized-wiki-ds.hf\")\n",
    "tokenized_ds"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T15:46:20.691819Z",
     "start_time": "2025-06-07T15:46:19.791243Z"
    }
   },
   "id": "3245c8d35c4a038c"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jacob/repos/reimplementing/.pixi/envs/default/lib/python3.13/site-packages/torch/nn/modules/transformer.py:385: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[' Theft', ' playable']"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "class PositionalEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim, device):\n",
    "        super().__init__()\n",
    "        self.numerators = 10_000 ** (  # TODO: Why 10_000?\n",
    "            torch.arange(\n",
    "                start=0,\n",
    "                end=embedding_dim,\n",
    "                step=2,\n",
    "                device=device,\n",
    "            ).float()\n",
    "            / embedding_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor):\n",
    "        with torch.no_grad():\n",
    "            positions = torch.arange(\n",
    "                input_ids.shape[1],\n",
    "                device=input_ids.device,\n",
    "            ).float()\n",
    "            raw_embeddings = positions.unsqueeze(1) @ (1 / self.numerators).unsqueeze(0)\n",
    "            even_embeddings = torch.sin(raw_embeddings)\n",
    "            odd_embeddings = torch.cos(raw_embeddings)\n",
    "            embeddings = torch.stack(\n",
    "                [even_embeddings, odd_embeddings], dim=-1\n",
    "            ).view(\n",
    "                len(positions), -1\n",
    "            )\n",
    "            return embeddings.unsqueeze(0).expand(input_ids.shape[0], -1, -1)\n",
    "\n",
    "\n",
    "token_embedder = nn.Embedding(\n",
    "    num_embeddings=tokenizer.vocab_size, embedding_dim=512, device=device\n",
    ")\n",
    "positional_embedder = PositionalEmbedding(embedding_dim=512, device=device)\n",
    "transformer_layer = nn.TransformerEncoderLayer(d_model=512, nhead=8, device=device)\n",
    "transformer = nn.TransformerEncoder(transformer_layer, num_layers=6)\n",
    "decoder = nn.Linear(512, tokenizer.vocab_size, device=device)\n",
    "\n",
    "src = [\"Hi, my name\", \"The United States of\"]\n",
    "tokenized = tokenizer(src, return_tensors=\"pt\").to(device)\n",
    "embedded = token_embedder(tokenized.input_ids) + positional_embedder(tokenized.input_ids)\n",
    "transformed = transformer(\n",
    "    embedded.permute(1, 0, 2),  # Transformer expects (seq_len, batch_size, features)\n",
    "    mask=nn.Transformer.generate_square_subsequent_mask(tokenized.input_ids.shape[1], device=device),\n",
    "    # Skipping is_causal since seems troublesome: https://github.com/pytorch/pytorch/issues/96941\n",
    ")\n",
    "logits = decoder(transformed.permute(1, 0, 2))  # Back to (batch_size, seq_len, features)\n",
    "result = tokenizer.batch_decode(logits[:, -1, :].argmax(dim=-1))\n",
    "result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T15:46:21.126936Z",
     "start_time": "2025-06-07T15:46:20.690283Z"
    }
   },
   "id": "8ddb9121087fad4e"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "MyGPT(\n  (token_embedder): Embedding(50257, 512)\n  (positional_embedder): PositionalEmbedding()\n  (transformer): TransformerEncoder(\n    (layers): ModuleList(\n      (0-5): 6 x TransformerEncoderLayer(\n        (self_attn): MultiheadAttention(\n          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n        )\n        (linear1): Linear(in_features=512, out_features=2048, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n        (linear2): Linear(in_features=2048, out_features=512, bias=True)\n        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n        (dropout1): Dropout(p=0.1, inplace=False)\n        (dropout2): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (decoder): Linear(in_features=512, out_features=50257, bias=True)\n)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyGPT(nn.Module):\n",
    "    def __init__(self, d_model, nhead, num_layers, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.token_embedder = nn.Embedding(\n",
    "            num_embeddings=tokenizer.vocab_size, embedding_dim=d_model, device=device\n",
    "        )\n",
    "        self.positional_embedder = PositionalEmbedding(embedding_dim=d_model, device=device)\n",
    "        self.transformer = nn.TransformerEncoder(\n",
    "            nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, device=device),\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.decoder = nn.Linear(d_model, tokenizer.vocab_size, device=device)\n",
    "\n",
    "    def forward(self, input_ids: torch.Tensor):\n",
    "        embedded = self.token_embedder(input_ids) + self.positional_embedder(input_ids)\n",
    "        transformed = self.transformer(\n",
    "            embedded.permute(1, 0, 2),  # Transformer expects (seq_len, batch_size, features)\n",
    "            mask=nn.Transformer.generate_square_subsequent_mask(input_ids.shape[1], device=input_ids.device),\n",
    "        )\n",
    "        logits = self.decoder(transformed.permute(1, 0, 2))\n",
    "        return logits\n",
    "    \n",
    "    def stream(self, input_ids: torch.Tensor, max_length=50):\n",
    "        # TODO: KV-cache to avoid quadratic computational complexity in `max_length`\n",
    "        output_ids = input_ids.clone()\n",
    "        for _ in range(max_length):\n",
    "            with torch.no_grad():\n",
    "                logits = self(output_ids)\n",
    "                # TODO: Support stochastic sampling\n",
    "                next_token_id = logits[:, -1, :].argmax(dim=-1, keepdim=True)\n",
    "                output_ids = torch.cat([output_ids, next_token_id], dim=1)\n",
    "                yield next_token_id.item()\n",
    "    \n",
    "    def print_stream(self, tokenizer, prompt: str, max_length=50):\n",
    "        print(prompt, end=\"\", flush=True)\n",
    "        input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(device)\n",
    "        for token in self.stream(input_ids, max_length=max_length):\n",
    "            if token == tokenizer.eos_token_id:\n",
    "                break\n",
    "            print(tokenizer.decode(token), end=\"\", flush=True)\n",
    "\n",
    "\n",
    "model = MyGPT(d_model=512, nhead=8, num_layers=6, device=device)\n",
    "model"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:02:34.969769Z",
     "start_time": "2025-06-07T16:02:34.611254Z"
    }
   },
   "id": "f0ce3a4d861100b7"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "[' affordable', ' Harden']"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(model(tokenizer(src, return_tensors=\"pt\").input_ids.to(device))[:, -1, :].argmax(dim=-1))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:02:37.680802Z",
     "start_time": "2025-06-07T16:02:37.652498Z"
    }
   },
   "id": "96d84dc850df0508"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The United States of cruise Plan777 inducing cruise Plan LS cruise Plan LS cruise Plan LS 13 clutching brandeddecl Contrast LS 13 LS 13 LS�� LS 13 LS 13 asleep Casribut Suppose� quicker Polyribut ``��elfth drinkersryptedimmigrant 106Bot LS��Chapter branded 106Bot\n",
      "The United States of cruise Plan cruise Plan LS deceased Corps deceased Corps cruiseAverage LIM 0000 clutchingRy LS 13 LS 13 LS�� LS 13 robbed assortment LS 13 entails................................................................ribut giveaway LS��catchACPChapter branded 106Botribut simul LSyre LS��Chapterribut Suppose 106 106\n",
      "The United States of Lakes bigger cruise moth cer cruise Plan LS cruise Plan LS 13 0000 106 designsyre LS 13 LS 13nesia LS 13zunesia LS�� LS 13 giveaway LS 13 giveawayribut Suppose 106 simul 106Bot 106Bot 13 simul branded simul 13 asleep === 13 simul\n",
      "The United States of stay cruise damaged disposed damaged Ninth cruise Plan LS cruise damaged quicker PolyguardsRy 106Ry LS cruiseyre LS `` 106 daemonRy LS Cas ``IFIED...... 106Bot ``akespeare clutchingRy 106 sus kernel 106Bot 106Bot 106 daemonRy 106 106Bot 106\n",
      "The United States of stay cruise PlanChapter Yoga cruise012 CK cruise affordableslice LS cruise cruise levels LS 13ACPChapter brandedzar Mercy trash 106 designs quicker iOS 106Victoria 106Bot 106 stocking Cas quicker adventure 106 designs quicker reconsider clutchingRy 106 designs strategy Love `` 106も Slovakia\n",
      "The United States of cruise Plan LS cruise Plan LS cruise Silicon cruise Plan LS cruiseAverage Marcus LS 13 LS 13 LSyre LS 13 coaching�� LS�� LS 13inguishableGs LS 13 LS 13�� Sed 13��elfth unarmed analogue LS 13impact inducing regain giveaway�� LS��\n",
      "The United States of Lakes cruise PlanChapter cruise clutching cruise cruise cruise prefix LS cruiseBot ticketChapter branded cruisedecl CK LS Casparen LS cruise clutching 0000 CasadjustVictoria LS Casadjust LS 13 clutching 106Bot 106Bot 106Bot 106 designs clutchingRy clutchingRy fetus 106Bot\n",
      "The United States of cruise moth fianceIntroduction 269 disposed Marcus 0000Ry LS cruise Siliconobby Marcus hover Art clutching 106Victoria LS 13 0000 Bone LS 13 LS 13 LS 13 clutchingRy 106Bot 106 designsyre Silicon LIMAverage quicker quicker reconsider clutchingRy 106Bot 106Bot 106akespeare\n",
      "The United States of cruise mothbda cruise Cummings possessedINAL cruise cruise iOSnesia Les cruiseilar clutching cruise branded brandedzar hoverzar trashVictoria LS LS LS 13 asleep LS 13 clutchingRy LS 13 clutching branded exclusively upright 13 asleep Korea clutching 106 designsyre LS�� Yoga 13Introduction\n",
      "The United States of stay stay cruise PlanChapter stayzarlo damaged quickerTokennesiaChapter branded cruise damaged quicker Paladin CKoti `` EarthquACP012................................................................Token 106 daemonvalid012 CK012 CK clutchingRy 106も� Contrast 106も� Pence Polyribut simul branded exclusively upright con\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    model.print_stream(tokenizer=tokenizer, prompt=\"The United States of\", max_length=50)\n",
    "    print(\"\", flush=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:04:21.035787Z",
     "start_time": "2025-06-07T16:04:10.054350Z"
    }
   },
   "id": "4ace6d0854424cb8"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "data": {
      "text/plain": "['',\n ' = Valkyria Chronicles III = \\n',\n '',\n ' Senjō no Valkyria 3 : <unk> Chronicles ( Japanese : 戦場のヴァルキュリア3 , lit . Valkyria of the Battlefield 3 ) , commonly referred to as Valkyria Chronicles III outside Japan , is a tactical role @-@ playing video game developed by Sega and Media.Vision for the PlayStation Portable . Released in January 2011 in Japan , it is the third game in the Valkyria series . Employing the same fusion of tactical and real @-@ time gameplay as its predecessors , the story runs parallel to the first game and follows the \" Nameless \" , a penal military unit serving the nation of Gallia during the Second Europan War who perform secret black operations and are pitted against the Imperial unit \" <unk> Raven \" . \\n',\n \" The game began development in 2010 , carrying over a large portion of the work done on Valkyria Chronicles II . While it retained the standard features of the series , it also underwent multiple adjustments , such as making the game more forgiving for series newcomers . Character designer <unk> Honjou and composer Hitoshi Sakimoto both returned from previous entries , along with Valkyria Chronicles II director Takeshi Ozawa . A large team of writers handled the script . The game 's opening theme was sung by May 'n . \\n\"]"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"][\"text\"][:5]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:08:56.678494Z",
     "start_time": "2025-06-07T16:08:56.675785Z"
    }
   },
   "id": "6e4c6dfba7ad523"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50256\n",
      "[{'input_ids': [17250]}, {'input_ids': [1820, 1438, 318]}, {'input_ids': [2061, 11, 616, 1438, 318]}]\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'input_ids': tensor([[17250, 50256, 50256, 50256, 50256],\n        [ 1820,  1438,   318, 50256, 50256],\n        [ 2061,    11,   616,  1438,   318]]), 'attention_mask': tensor([[1, 0, 0, 0, 0],\n        [1, 1, 1, 0, 0],\n        [1, 1, 1, 1, 1]])}"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tokenizer.pad_token_id)\n",
    "tokenized = [\n",
    "    {\n",
    "        \"input_ids\": tokenizer(s, return_tensors=\"pt\").input_ids.flatten().tolist()\n",
    "    }\n",
    "    for s in [\"Hi\", \"my name is\", \"What, my name is\"]\n",
    "]\n",
    "print(tokenized)\n",
    "tokenizer.pad(tokenized, return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:32:39.852108Z",
     "start_time": "2025-06-07T16:32:39.848066Z"
    }
   },
   "id": "fdcc1c99617a3870"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0: Loss 8.02338981628418\n",
      "The United States of the the the of the the the the , the the the and of the the of of the of the , the in the the the the the of of the of of the the the of a the the the of the the the of , the of\n",
      "Avg. validation Loss 7.778955459594727\n",
      "Batch 25: Loss 7.6177825927734375\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "train_dl = DataLoader(\n",
    "    tokenized_ds[\"train\"],\n",
    "    batch_size=256,\n",
    "    shuffle=True,\n",
    "    collate_fn=lambda x: tokenizer.pad(x, return_tensors=\"pt\"),\n",
    ")\n",
    "validation_dl = DataLoader(\n",
    "    tokenized_ds[\"validation\"],\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    collate_fn=lambda x: tokenizer.pad(x, return_tensors=\"pt\"),\n",
    ")\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "log_frequency = 25\n",
    "stream_frequency = 100\n",
    "eval_frequency = 250\n",
    "\n",
    "model.train()\n",
    "train_losses = []\n",
    "eval_losses = []\n",
    "for batch_i, batch in enumerate(train_dl):\n",
    "    X: torch.Tensor = batch.input_ids.to(device)[:, :-1].contiguous()\n",
    "    y: torch.Tensor = batch.input_ids.to(device)[:, 1:].contiguous()\n",
    "    logits = model(X)\n",
    "    loss = nn.functional.cross_entropy(\n",
    "        logits.view(-1, logits.shape[-1]),\n",
    "        y.view(-1),\n",
    "        ignore_index=tokenizer.pad_token_id,\n",
    "    )\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    if batch_i % log_frequency == 0:\n",
    "        train_losses.append(loss.item())\n",
    "        print(f\"Batch {batch_i}: Loss {loss.item()}\")\n",
    "    \n",
    "    if batch_i % stream_frequency == 0:\n",
    "        model.print_stream(tokenizer=tokenizer, prompt=\"The United States of\", max_length=50)\n",
    "        print(\"\", flush=True)\n",
    "    \n",
    "    if batch_i % eval_frequency == 0:\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            avg_val_loss = 0.0\n",
    "            for validation_batch in validation_dl:\n",
    "                X_val: torch.Tensor = validation_batch.input_ids.to(device)[:, :-1].contiguous()\n",
    "                y_val: torch.Tensor = validation_batch.input_ids.to(device)[:, 1:].contiguous()\n",
    "                val_logits = model(X_val)\n",
    "                avg_val_loss += nn.functional.cross_entropy(\n",
    "                    val_logits.view(-1, val_logits.shape[-1]),\n",
    "                    y_val.view(-1),\n",
    "                    ignore_index=tokenizer.pad_token_id,\n",
    "                ) / len(validation_dl)\n",
    "            eval_losses.append(avg_val_loss.item())\n",
    "            print(f\"Avg. validation Loss {avg_val_loss.item()}\")\n",
    "            model.train()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2025-06-07T16:57:10.541613Z"
    }
   },
   "id": "c2edb01b55dd928b"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "data": {
      "text/plain": "86.9296875"
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_loss_batch_i = np.arange(len(train_losses)) * log_frequency\n",
    "eval_loss_batch_i = np.arange(len(eval_losses)) * eval_frequency\n",
    "plt.plot(train_loss_batch_i, train_losses, \"--o\", label=\"Train Loss\")\n",
    "plt.plot(eval_loss_batch_i, eval_losses, \"--o\", label=\"Eval Loss\")\n",
    "plt.xlabel(\"Batch number\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss over batches\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:52:09.237756Z",
     "start_time": "2025-06-07T16:52:09.236231Z"
    }
   },
   "id": "1fa68a4ee65e2f92"
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[65]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mpad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mHi\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mmy name is\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mWhat, my name is\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[43m=\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mpt\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/repos/reimplementing/.pixi/envs/default/lib/python3.13/site-packages/transformers/tokenization_utils_base.py:3326\u001B[39m, in \u001B[36mPreTrainedTokenizerBase.pad\u001B[39m\u001B[34m(self, encoded_inputs, padding, max_length, pad_to_multiple_of, padding_side, return_attention_mask, return_tensors, verbose)\u001B[39m\n\u001B[32m   3322\u001B[39m \u001B[38;5;66;03m# The model's main input name, usually `input_ids`, has been passed for padding\u001B[39;00m\n\u001B[32m   3323\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.model_input_names[\u001B[32m0\u001B[39m] \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m encoded_inputs:\n\u001B[32m   3324\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   3325\u001B[39m         \u001B[33m\"\u001B[39m\u001B[33mYou should supply an encoding or a list of encodings to this method \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m-> \u001B[39m\u001B[32m3326\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mthat includes \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m.model_input_names[\u001B[32m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, but you provided \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mlist\u001B[39m(\u001B[43mencoded_inputs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mkeys\u001B[49m())\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m\n\u001B[32m   3327\u001B[39m     )\n\u001B[32m   3329\u001B[39m required_input = encoded_inputs[\u001B[38;5;28mself\u001B[39m.model_input_names[\u001B[32m0\u001B[39m]]\n\u001B[32m   3331\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m required_input \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m (\u001B[38;5;28misinstance\u001B[39m(required_input, Sized) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(required_input) == \u001B[32m0\u001B[39m):\n",
      "\u001B[31mAttributeError\u001B[39m: 'list' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "tokenizer.pad(, return_tensors=\"pt\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T16:28:21.526964Z",
     "start_time": "2025-06-07T16:28:21.498414Z"
    }
   },
   "id": "41f60b68096ae5c5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b0f27dc6f6b6c6d1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
